import logging
from pathlib import Path
from opensearchpy import OpenSearch, RequestsHttpConnection, OpenSearchException

from knowledge_flow_app.stores.metadata.base_metadata_store import BaseMetadataStore

logger = logging.getLogger(__name__)

class OpenSearchMetadataStore(BaseMetadataStore):

    def __init__(self, 
                 host: str, 
                 metadata_index_name: str,
                 vector_index_name: str, 
                 username: str = None,
                 password: str = None,
                 secure: bool = False,
                 verify_certs: bool = False):
        self.client = OpenSearch(
            host,
            http_auth=(username, password),
            use_ssl=secure,
            verify_certs=verify_certs,
            connection_class=RequestsHttpConnection,
        )
        self.metadata_index_name = metadata_index_name
        self.vector_index_name = vector_index_name

        if not self.client.indices.exists(index=metadata_index_name):
            self.client.indices.create(index=metadata_index_name)
            logger.info(f"Opensearch index '{metadata_index_name}' created.")
        else:
            logger.warning(f"Opensearch index '{metadata_index_name}' already exists.")


    def get_metadata_by_uid(self, document_uid: str) -> dict:
        """Fetch metadata of a specific document by UID."""
        try:
            response = self.client.get(index=self.metadata_index_name, id=document_uid)
            if response["found"]:
                source = response["_source"]
                # Extract and merge main metadata with front_metadata
                front_metadata = source.pop("front_metadata", {})
                combined_metadata = {**source, **front_metadata}
                return combined_metadata
            else:
                return {}
        except Exception as e:
            logger.error(f"Error while retrieving metadata for UID '{document_uid}': {e}")
            return {}
        
    def uid_exists(self, document_uid: str) -> bool:
        try:
            return self.client.exists(index=self.metadata_index_name, id=document_uid)
        except Exception as e:
            logger.error(f"Error while checking existence of UID '{document_uid}' in OpenSearch: {e}")
            return False
        
    def write_metadata(self, document_uid: str, metadata: dict):
        """Write metadata to OpenSearch using the UID as document ID."""
        try:
            response = self.client.index(
                index=self.metadata_index_name,
                id=document_uid,
                body=metadata
            )
            logger.info(f"Metadata written to index '{self.metadata_index_name}' for UID '{document_uid}'.")
            return response
        except OpenSearchException as e:
            logger.error(f"❌ Failed to write metadata with UID {document_uid}: {e}")
            raise ValueError(f"Failed to write metadata to Opensearch: {e}")

 
    def update_metadata_field(self, document_uid: str, field: str, value: any):
        try:
            # 1) Partial update of the document in the metadata index
            response_meta = self.client.update(
                index=self.metadata_index_name,
                id=document_uid,
                body={"doc": {field: value}}
            )
            logger.info(f"[METADATA INDEX] Field '{field}' updated for UID '{document_uid}' => {value}")
            # 2) Update (in bulk) chunks in the "vector store" index
            #    - The Painless script will set `ctx._source.metadata.<field>`
            #      to the new value.
            #    - This is done to ensure that the vector index is in sync with the metadata index.
            #    - The field name is prefixed with "metadata." to match the structure in the vector index.
            #    - The script is executed in the context of each document being updated.
            #    - The `params.value` is passed to the script as a parameter.
            #    - The `document_uid` is used to filter the documents to be updated.
            #    - The `term` query is used to match the documents with the specified UID.
            #    - The `update_by_query` API is used to update all matching documents in the vector index.
            script_source = f"ctx._source.metadata.{field} = params.value"
            query_body = {
                "script": {
                    "source": script_source,
                    "lang": "painless",
                    "params": {"value": value}
                },
                "query": {
                    "term": {
                        "metadata.document_uid": document_uid
                    }
                }
            }

            response_vector = self.client.update_by_query(
                index=self.vector_index_name,
                body=query_body
            )
            logger.info(
                f"[VECTOR INDEX] Field 'metadata.{field}' updated for "
                f"all chunks with UID='{document_uid}' => {value}"
            )

            return {
                "metadata_index_response": response_meta,
                "vector_index_response": response_vector
            }
        except Exception as e:
            logger.error(f"Error while updating field '{field}' for UID '{document_uid}': {e}")
            raise e

    def get_all_metadata(self, filters_dict: dict):
        """
        Retrieve all document metadata from the index,
        optionally filtered by provided parameters.
        filters_dict is a dict like {"GBU": "TAS", "BU": "X", ...}
        """
        try:
            must_clauses = []
            # For each parameter, build a term query
            # Ex.: field_name="GBU", field_value="TAS"
            for field_name, field_value in filters_dict.items():
                clause = {
                    "term": {f"front_metadata.{field_name}.keyword": field_value}
                }
                must_clauses.append(clause)

            if not must_clauses:
                # If no parameters were passed, do a match_all
                # This will return all documents in the index
                query = {"match_all": {}}
            else:
                # Combine all filters into a bool must
                # This will return documents that match all the filters
                query = {
                    "bool": {
                        "must": must_clauses
                    }
                }

            response = self.client.search(
                index=self.metadata_index_name,
                body={"query": query},
                _source=[
                    "document_name", 
                    "document_uid", 
                    "date_added_to_kb", 
                    "retrievable", 
                    "front_metadata"
                ],
                size=1000
            )

            hits = response["hits"]["hits"]
            # Merge _source and front_metadata if we want a single object per doc
            # This will create a list of documents with merged metadata
            documents = []
            for h in hits:
                src = h["_source"].copy()
                front_metadata = src.pop("front_metadata", {})
                merged = {**src, **front_metadata}
                documents.append(merged)

            return documents

        except Exception as e:
            logger.error(f"Error while retrieving metadata: {e}")
            return []
        
    def delete_metadata(self, metadata: dict):
        """Delete metadata from OpenSearch using the UID."""
        try:
            document_uid = metadata.get("document_uid")
            if not document_uid:
                raise ValueError("Missing 'document_uid' in metadata.")

            # Delete from the metadata index
            self.client.delete(index=self.metadata_index_name, id=document_uid)
            logger.info(f"Metadata with UID '{document_uid}' deleted from index '{self.metadata_index_name}'.")

            # Delete from the vector index
            self.client.delete(index=self.vector_index_name, id=document_uid)
            logger.info(f"Metadata with UID '{document_uid}' deleted from index '{self.vector_index_name}'.")

        except Exception as e:
            logger.error(f"Error while deleting metadata for UID '{metadata.get('document_uid', 'N/A')}': {e}")
            raise e

    def save_metadata(self, metadata: dict):
        """Save metadata in Opensearch

        Args:
            metadata (dict): A dictionary containing metadatas
        """
        try:
            self.write_metadata(document_uid=metadata.get("document_uid"), metadata=metadata)
        except Exception as e:
            logger.error(f"❌ Failed to write metadata with UID {metadata.get("document_uid")}: {e}")
            raise ValueError(e)